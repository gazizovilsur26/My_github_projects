# Проект по восстановлению золота из руды
## Описание проекта
Задача проекта заключается в разработке прототипа модели машинного обучения для компании, чтобы предсказывать коэффициент восстановления золота из золотосодержащей руды на основе данных о параметрах добычи и очистки, с целью оптимизации производства и избегания запуска предприятия с убыточными характеристиками в золотодобывающей отрасли
## Навыки и инструменты
* python
* pandas
* numpy
* scipy
* sklearn.model_selection.cross_val_score
* sklearn.metrics.mean_squared_error
* sklearn.metrics.mean_absolute_error
* sklearn.preprocessing.StandardScaler
* sklearn.linear_model.LinearRegression
* sklearn.tree.DecisionTreeRegressor
* sklearn.ensemble.RandomForestRegressor
* matplotlib
## Общий вывод

## Что было сделано
* Провели предобработку данных: 
    - Явных дубликатов не было; 
    - Пропуски заполнили средними соседних значений методом `interpolate`, так как в данных наблюдается зависимость от времени (близкие по времени объекты имеют близкие значения)
    - Проверили формулу вычисления эффективности обогащения. Всё хорошо, вычисленные формулой значения совпадают с данными из датасета (`MAE = 0.0`)
    - Проанализировали признаки, отсутсвующие в тестовой выборке: отсутствующие признаки относятся к выходным output. Удалили из тренировочной модели признаки, отсутсвующие в тестовой выборке
* Провели исследовательский анализ данных: 
    - Удалили выбросы из распределений концентраций Au, Ag, Pb на разных этапах обработки
    - Проанализировали распределения размеров гранул на обучающей и тестовой выборках. Распределения размеров гранул для тестовой и тренировочной выборок не отличаются друг от друг. Всё хорошо, значит они по природе своей не отличаются. Можно обучать
    - Исследовали суммарные концентрации Au, Ag, Pb на разных стадиях. Суммарная концентрация веществ увеличивается к финальному этапу. При этом дисперсия их распределения уменьшается. Выбросов нет
    - Разделили датасет на 2 части - на `df_train_rougher` и `df_train_final`, чтобы обучить две разные модели не на одних и тех же признаках, а на разных, соответтсвующих как раз раным этапам обработки
    - Избавились от мультиколлинеарности признаков тренировочных данных
* Написали функции для вычисления итогового sMAPE
* Обучили и проверили несколько моделей:
    - Лучшие результаты на кросс-валидации показали: `model_lr = LinearRegression()` для этапа rougher (`smape = 5.99`), `rs_rf_final = RandomForestRegressor('n_estimators': 1141, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 6)` (`smape = 9.19`)
    - Эти модели тестовой выборке показали
        - `Smape rougher: 8.01`
        - `Smape final: 10.00`
        - ${Smape\;total} = 0.25 \cdot{Smape\;rougher} + 0.75 \cdot{Smape\;final} = 9.50$
* Проверили модель на адекватность: `smape нашей модели 9.50, что ниже чем 9.79 константной модели`. Значит наша модель эффективна
